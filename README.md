âš ï¸ *Alert: This is Ongoing Project (Planning Level)*

[Project Prototype Planning](https://fairydata.notion.site/49b72350b1074fb094e0ec792cff7d59?pvs=4)

# **LLM-based Phoneme-level Korean Pronunciation Correction for Japanese Native Speakers**ğŸ§‘â€ğŸ«ğŸ“
[![ì˜ìƒ ì œëª©](https://img.youtube.com/vi/4SwwmzEcpZQ/0.jpg)](https://youtu.be/4SwwmzEcpZQ)<br>
A project focused on building a **pronunciation correction system** for Japanese native speakers learning Korean, using Whisper and Wav2Vec 2.0 for analyzing intended and actual pronunciation. The system identifies pronunciation errors and provides targeted feedback to help improve Korean pronunciation effectively.

---

## **Table of Contents**

1. [Overview](#overview)
2. [Features](#features)
3. [Installation](#installation)
4. [Usage](#usage)
5. [Example](#example)
6. [Feedback and Contribution](#feedback-and-contribution)
7. [License](#license)

---

### **Overview**

This project addresses the growing demand for Korean language education among Japanese native speakers. As the number of Japanese learners of Korean continues to rise, accurate pronunciation remains a significant challenge, with limited resources tailored to Japanese speakers. This project combines **Whisper** and **Wav2Vec 2.0** to build an effective pronunciation correction system. Whisper determines the intended pronunciation, while Wav2Vec 2.0 analyzes the actual phonetic output, effectively identifying discrepancies and providing feedback. Additionally, **language detection** is used to handle code-switching between Korean and Japanese, ensuring high accuracy in mixed-language conversations.

### **Features**

- **Market Demand-Driven Solution**: Responds to the rapid growth of Korean learners in Japan, where existing resources often lack focus on pronunciation training.
- **Error Detection**: Detects specific pronunciation errors by comparing intended versus actual phonemes.
- **Targeted Feedback**: Provides corrective suggestions designed for Japanese speakers learning Korean.
- **Language Detection**: Handles code-switching (æ··åˆè¨€èª), making it compatible with conversations that switch between Korean and Japanese.
- **User-Friendly Interface**: Accessible via a web interface built with Streamlit.

---

### **Installation**

To set up this project locally, follow these steps:

1. **Clone the Repository**:
   ```bash
   git clone https://github.com/fairyofdata/JP2KR_PhonemeTutor
   cd fairyofdata/JP2KR_PhonemeTutor
   ```

2. **Install Required Packages**:
   - Make sure you have Python installed (version 3.8+ recommended).
   - Install the dependencies:
     ```bash
     pip install -r requirements.txt
     ```

3. **Set Up API Keys**:
   - If using Whisperâ€™s API, make sure to set up and configure your OpenAI API key.
   - Add your API key to your environment variables or a `.env` file.

---

### **Usage**

Once installed, you can use the system as follows:

1. **Running the Web Interface**:
   - Start the Streamlit app for a user-friendly interface.
   ```bash
   streamlit run app.py
   ```

2. **Uploading Audio Files**:
   - Users can upload audio files (e.g., extracted from conversation videos).
   - The system will automatically detect code-switching and separate Korean and Japanese sections.

3. **Receiving Pronunciation Feedback**:
   - After processing, the system displays targeted feedback for incorrect pronunciations, highlighting specific phonemes and syllables that require improvement.

---

### **Example**

Hereâ€™s a step-by-step example of how to use the system:

1. **Upload an audio file** where a Japanese speaker is speaking Korean. Make sure the audio is clear for better results.
2. **The system detects intended pronunciation** using Whisper and analyzes actual pronunciation with Wav2Vec 2.0.
3. **View Feedback**: The output will highlight the mispronounced syllables and provide recommendations for improvement.

**æ—¥æœ¬èªèª¬æ˜ (Japanese Explanation)**:
1. **ã‚ªãƒ¼ãƒ‡ã‚£ã‚ªãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„**ã€‚æ—¥æœ¬äººè©±è€…ãŒéŸ“å›½èªã‚’è©±ã—ã¦ã„ã‚‹éŸ³å£°ã§ã™ã€‚
2. **æ„å›³ã—ãŸç™ºéŸ³ã‚’WhisperãŒåˆ†æã—**ã€Wav2Vec 2.0ãŒå®Ÿéš›ã®ç™ºéŸ³ã‚’ç¢ºèªã—ã¾ã™ã€‚
3. **ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã‚’å—ã‘å–ã‚‹**ï¼šé–“é•ã£ãŸç™ºéŸ³ç®‡æ‰€ãŒå¼·èª¿è¡¨ç¤ºã•ã‚Œã€æ”¹å–„ã®ãŸã‚ã®ã‚¢ãƒ‰ãƒã‚¤ã‚¹ãŒæä¾›ã•ã‚Œã¾ã™ã€‚

---

### **Feedback and Contribution**

We welcome contributions from the community! If you would like to suggest improvements, report bugs, or request new features, please submit an issue or a pull request.

### **License**

This project is licensed under the MIT License. See the [LICENSE](LICENSE) file for details.
